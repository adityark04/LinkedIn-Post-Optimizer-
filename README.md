<div align="center">
<img width="1200" height="475" alt="GHBanner" src="https://github.com/user-attachments/assets/0aa67016-6eaf-458a-adb2-6e31a0763ed6" />
</div>

# AI LinkedIn Post Optimizer

A full-stack web application that uses **three custom-trained deep learning models** to optimize LinkedIn posts. This project demonstrates real-world applications of CNNs, Transformers, and Transfer Learning.

## ğŸ¯ Project Overview

Transform your draft LinkedIn posts into three professionally optimized versions:

1. **Transformer-Generated** - Adds engaging hooks and attention-grabbing openings
2. **CNN-Enhanced** - Creates concise, punchy versions that get to the point
3. **T5-Rephrased** - Generates SEO-optimized, professional versions

### Deep Learning Models Used

- **Custom Transformer** (Encoder-Decoder with Multi-Head Attention)
- **CNN for Text** (1D Convolutions with Multiple Filter Sizes)
- **Fine-tuned T5** (Hugging Face Pre-trained Model)

**No external APIs or GPT services** - All models are trained and run locally!

---

## ğŸ—ï¸ Architecture

```
Frontend (React + TypeScript + Vite)
    â†“
Flask REST API (Python)
    â†“
ML Model Service
    â”œâ”€â”€ Transformer Model (Hook Generation)
    â”œâ”€â”€ CNN Model (Concise Generation)
    â””â”€â”€ T5 Model (Rephrasing)
```

---

## ğŸ“‹ Prerequisites

- **Node.js** (v16 or higher)
- **Python** 3.8+ 
- **pip** (Python package manager)

---

## ğŸš€ Quick Start

### Step 1: Install Frontend Dependencies

```powershell
npm install
```

### Step 2: Install Backend Dependencies

```powershell
cd backend
pip install -r requirements.txt
```

This installs PyTorch, Transformers, Flask, and other ML libraries.

### Step 3: Train the Models

**IMPORTANT:** You must train the models before running the application.

```powershell
# Generate dataset
python prepare_dataset.py

# Train all three models (takes ~20-30 minutes on CPU)
python train_models.py
```

See [TRAINING_GUIDE.md](TRAINING_GUIDE.md) for detailed training instructions.

### Step 4: Run the Application

**Terminal 1 - Start Backend:**
```powershell
cd backend
python app.py
```

**Terminal 2 - Start Frontend:**
```powershell
npm run dev
```

**Open your browser:** http://localhost:5173

---

## ğŸ“– Detailed Documentation

- **[TRAINING_GUIDE.md](TRAINING_GUIDE.md)** - Complete guide to training models
- **Model architectures** - See `backend/models/` directory
- **API documentation** - See `backend/app.py`

---

## ğŸ§  Deep Learning Concepts Demonstrated

### 1. Transformer Model (`transformer_model.py`)
- âœ… Multi-head self-attention
- âœ… Positional encoding
- âœ… Encoder-decoder architecture
- âœ… Masked attention (prevents looking ahead)
- âœ… Beam search decoding

### 2. CNN Model (`cnn_model.py`)
- âœ… 1D Convolutions for text
- âœ… Multiple kernel sizes (3, 4, 5)
- âœ… Max pooling
- âœ… Feature extraction
- âœ… Sequence-to-sequence generation

### 3. T5 Model (Hugging Face)
- âœ… Transfer learning
- âœ… Fine-tuning pre-trained models
- âœ… Text-to-text transformation
- âœ… Conditional generation

---

## ğŸ“ Project Structure

```
ai-linkedin-post-optimizer/
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ App.tsx              # Main React component
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â””â”€â”€ apiService.ts    # API calls to backend
â”‚   â””â”€â”€ components/          # UI components
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app.py              # Flask API server
â”‚   â”œâ”€â”€ ml_model_service.py # Model loading and inference
â”‚   â”œâ”€â”€ prepare_dataset.py  # Dataset generation
â”‚   â”œâ”€â”€ train_models.py     # Training script
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ transformer_model.py  # Custom Transformer
â”‚   â”‚   â”œâ”€â”€ cnn_model.py          # CNN for text
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”œâ”€â”€ data/               # Training data (generated)
â”‚   â”œâ”€â”€ saved_models/       # Trained model weights
â”‚   â””â”€â”€ requirements.txt    # Python dependencies
â”œâ”€â”€ TRAINING_GUIDE.md       # Detailed training guide
â””â”€â”€ README.md              # This file
```

---

## ğŸ“ Educational Value

This project is perfect for learning:

1. **End-to-end ML pipeline** - From data preparation to deployment
2. **Multiple DL architectures** - CNNs, Transformers, Transfer Learning
3. **Full-stack integration** - Connecting ML models to web applications
4. **PyTorch fundamentals** - Model building, training, and inference
5. **Production considerations** - Model serving, error handling

---

## ğŸ”§ Training Details

### Dataset
- Synthetic LinkedIn posts generated in `prepare_dataset.py`
- Each sample has 4 versions: draft, hook, concise, rephrased
- 80/20 train/test split

### Training Time (CPU)
- Transformer: ~10-15 minutes (30 epochs)
- CNN: ~8-10 minutes (30 epochs)
- T5: ~5-10 minutes (5 epochs)
- **Total: ~20-30 minutes**

### Model Sizes
- Vocabulary: ~200-500 words
- Transformer: ~2-3 MB
- CNN: ~1-2 MB
- T5: ~242 MB (pre-trained model)

---

## ğŸ¨ Features

- âœ… Real-time post optimization
- âœ… Three different AI styles
- âœ… Copy-to-clipboard functionality
- âœ… Dark theme UI
- âœ… Responsive design
- âœ… Error handling
- âœ… Loading states

---

## ğŸ› ï¸ Customization

### Add More Training Data

Edit `backend/prepare_dataset.py` to add more examples:

```python
drafts = [
    "Your new LinkedIn draft...",
    # Add more
]
```

Then retrain:
```powershell
python prepare_dataset.py
python train_models.py
```

### Adjust Model Architecture

Modify hyperparameters in `train_models.py`:

```python
model = TransformerHookGenerator(
    d_model=256,      # Increase for larger model
    nhead=8,          # More attention heads
    num_encoder_layers=3,  # Deeper network
)
```

---

## ğŸ› Troubleshooting

### "Models Not Trained" Error
**Solution:** Run `python train_models.py` in the backend directory.

### NLTK Download Errors
**Solution:** 
```powershell
python -c "import nltk; nltk.download('punkt')"
```

### PyTorch Installation Issues
**Solution:** Use CPU-only version:
```powershell
pip install torch --index-url https://download.pytorch.org/whl/cpu
```

### Memory Issues During Training
**Solution:** Reduce batch size in `train_models.py` from 4 to 2 or 1.

---

## ğŸ“Š Model Performance

After training, models will:
- Generate contextually relevant hooks
- Create meaningful summaries
- Rephrase in professional LinkedIn style

**Note:** Performance improves with more training data!

---

## ğŸš€ Future Enhancements

- [ ] Add more training data (real LinkedIn posts)
- [ ] Implement user feedback loop
- [ ] Add model evaluation metrics
- [ ] GPU acceleration support
- [ ] Model comparison dashboard
- [ ] Export to LinkedIn directly

---

## ğŸ“ License

This project is for educational purposes.

---

## ğŸ™ Acknowledgments

- PyTorch for deep learning framework
- Hugging Face for Transformers library
- React team for frontend framework

---

## ğŸ“§ Support

For issues or questions:
1. Check [TRAINING_GUIDE.md](TRAINING_GUIDE.md)
2. Review error messages carefully
3. Ensure all dependencies are installed

---

**Happy Learning! ğŸ“**
